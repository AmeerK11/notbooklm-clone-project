# Embedding Provider Configuration
# Choose one of: "local", "openai", "huggingface" (default: "local")
EMBEDDING_PROVIDER=local

# If using "openai" provider:
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
ELEVENLABS_API_KEY=elv_xxxxxxxxxxxxxxxxxxxxxxxx

# If using "huggingface" provider:
# Get your token from https://huggingface.co/settings/tokens
HF_API_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxx

# Model names (optional; defaults are reasonable)
# For "local" provider (sentence-transformers models):
#   Recommended: "all-MiniLM-L6-v2" (lightweight, ~2GB memory)
#   Larger: "all-mpnet-base-v2", "all-roberta-large-v1"
EMBEDDING_MODEL=all-MiniLM-L6-v2

# For "openai" provider:
#   Options: "text-embedding-3-small", "text-embedding-3-large"
# EMBEDDING_MODEL=text-embedding-3-small

# For "huggingface" provider:
#   Recommended: "sentence-transformers/all-MiniLM-L6-v2"
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Storage base directory (optional; defaults to ./data)
# STORAGE_BASE_DIR=./data

# Chroma persistence directory (optional; defaults to in-memory)
# CHROMA_PERSIST_DIR=./chroma_data

# ------------------------------------------------------------------------------
# Artifact + TTS Configuration
# ------------------------------------------------------------------------------
# LLM model used by report/quiz generation (OpenAI client in current code)
LLM_MODEL=gpt-4o-mini

# Podcast transcript LLM provider + model
# Providers: openai | groq | ollama
TRANSCRIPT_LLM_PROVIDER=openai
# If not set, defaults depend on provider:
#   openai -> gpt-4o-mini
#   groq   -> llama-3.1-8b-instant
#   ollama -> qwen2.5:3b
TRANSCRIPT_LLM_MODEL=

# Groq (if TRANSCRIPT_LLM_PROVIDER=groq)
# GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxx
# GROQ_MODEL=llama-3.1-8b-instant

# Ollama (if TRANSCRIPT_LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://127.0.0.1:11434

# Podcast defaults
DEFAULT_PODCAST_DURATION=5min
PODCAST_HOST_1=Alex
PODCAST_HOST_2=Jordan

# TTS provider: "edge" (free), "openai", or "elevenlabs"
TTS_PROVIDER=edge

# OpenAI TTS (if TTS_PROVIDER=openai)
TTS_MODEL=tts-1
TTS_OPENAI_VOICE_1=alloy
TTS_OPENAI_VOICE_2=echo

# ElevenLabs TTS (if TTS_PROVIDER=elevenlabs)
# ELEVENLABS_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxx
TTS_ELEVENLABS_VOICE_1=Antoni
TTS_ELEVENLABS_VOICE_2=Rachel

# Edge TTS (if TTS_PROVIDER=edge)
TTS_EDGE_VOICE_1=en-US-GuyNeural
TTS_EDGE_VOICE_2=en-US-AriaNeural

# ------------------------------------------------------------------------------
# Authentication
# ------------------------------------------------------------------------------
# AUTH_MODE options:
#   - dev: local/test mode with optional /auth/dev-login helper
#   - hf_oauth: Hugging Face OAuth flow
AUTH_MODE=dev

# Session signing secret for backend cookies
APP_SESSION_SECRET=replace-with-a-random-secret
# Session cookie hardening (set secure=true in HTTPS deployments)
# SESSION_COOKIE_SECURE=true
# SESSION_COOKIE_SAMESITE=lax

# Bridge token TTL (seconds) used to hand off OAuth login back to Streamlit
AUTH_BRIDGE_TOKEN_TTL_SECONDS=300

# Dev auth defaults (used when AUTH_MODE=dev)
AUTH_DEV_USER_ID=1
AUTH_DEV_EMAIL=dev@example.com
AUTH_DEV_DISPLAY_NAME=Dev User

# HF OAuth settings (required when AUTH_MODE=hf_oauth)
# HF_OAUTH_CLIENT_ID=
# HF_OAUTH_CLIENT_SECRET=
# HF_OAUTH_REDIRECT_URI=
# HF_OAUTH_SCOPE=openid profile email
# HF_OAUTH_AUTHORIZE_URL=https://huggingface.co/oauth/authorize
# HF_OAUTH_TOKEN_URL=https://huggingface.co/oauth/token
# HF_OAUTH_USERINFO_URL=https://huggingface.co/oauth/userinfo
# AUTH_SUCCESS_REDIRECT_URL=http://127.0.0.1:8501

# ------------------------------------------------------------------------------
# Streamlit Server (useful for HF Spaces/proxy behavior)
# ------------------------------------------------------------------------------
# Set false only if upload endpoint fails behind proxy with 403.
# STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION=false
# STREAMLIT_SERVER_ENABLE_CORS=false
# STREAMLIT_SERVER_MAX_UPLOAD_SIZE=200
